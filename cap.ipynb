{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0876b126-d282-49d2-bba9-e0df1ca589cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time [hh:mm:ss]</th>\n",
       "      <th>Event</th>\n",
       "      <th>Duration[s]</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22:30:28</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22:30:58</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22:31:28</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22:31:58</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22:32:28</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>06:05:58</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>06:06:28</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>06:06:58</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>06:07:28</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>06:07:58</td>\n",
       "      <td>SLEEP-S0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1225 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Time [hh:mm:ss]     Event  Duration[s]  Class\n",
       "0           22:30:28  SLEEP-S0           30      0\n",
       "1           22:30:58  SLEEP-S0           30      0\n",
       "2           22:31:28  SLEEP-S0           30      0\n",
       "3           22:31:58  SLEEP-S0           30      0\n",
       "4           22:32:28  SLEEP-S0           30      0\n",
       "...              ...       ...          ...    ...\n",
       "1220        06:05:58  SLEEP-S0           30      0\n",
       "1221        06:06:28  SLEEP-S0           30      0\n",
       "1222        06:06:58  SLEEP-S0           30      0\n",
       "1223        06:07:28  SLEEP-S0           30      0\n",
       "1224        06:07:58  SLEEP-S0           30      0\n",
       "\n",
       "[1225 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins1.txt\"\n",
    "            \n",
    "\n",
    "\n",
    "data = pd.read_csv(file_path, sep=\"\\t\", skiprows=20, usecols=[\"Time [hh:mm:ss]\", \"Event\", \"Duration[s]\", \"Location\"])\n",
    "\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "data['Class'] = ((data['Event'].str.contains(\"MCAP\", na=False)) & \n",
    "                 (data['Location'] == \"EEG-Fp2-F4\")).astype(int)\n",
    "\n",
    "# Preview the cleaned and filtered dataset\n",
    "filtered_data = data[[\"Time [hh:mm:ss]\", \"Event\", \"Duration[s]\", \"Class\"]]\n",
    "filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd00c2f-4db0-4658-b84d-a606b195cae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to: C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_file_path = r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\filtered_data.csv\"\n",
    "filtered_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Filtered data saved to: {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "675b98f1-b71a-4f23-8d07-2a98179f0339",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\epoch_features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "547fb422-fe15-4e05-ad80-87988e7d0322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[271,   1],\n",
       "        [  4,  92]], dtype=int64),\n",
       " 0.9864130434782609,\n",
       " 0.989247311827957)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "\n",
    "# Drop rows with missing values and separate features and target\n",
    "data_cleaned = data1.dropna()\n",
    "X = data_cleaned.drop(columns=[\"Class\", \"Time [hh:mm:ss]\"])\n",
    "y = data_cleaned[\"Class\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "conf_matrix, accuracy, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c222733-cf49-4d94-ada6-ee67432a5c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to: C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\combined_data.csv\n",
      "  Time [hh:mm:ss]     Event  Duration[s]   Location  Class\n",
      "0        22:30:28  SLEEP-S0           30  EMG1-EMG2      0\n",
      "1        22:30:58  SLEEP-S0           30  EMG1-EMG2      0\n",
      "2        22:31:28  SLEEP-S0           30  EMG1-EMG2      0\n",
      "3        22:31:58  SLEEP-S0           30  EMG1-EMG2      0\n",
      "4        22:32:28  SLEEP-S0           30  EMG1-EMG2      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# List of file paths\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins1.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins2.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins3.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins4.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins5.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins6.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins7.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins8.txt\",\n",
    "    r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins9.txt\",\n",
    "]\n",
    "\n",
    "# Initialize an empty DataFrame to store combined data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Process each file\n",
    "for file_path in file_paths:\n",
    "    # Read the file\n",
    "    data = pd.read_csv(file_path, sep=\"\\t\", skiprows=20, usecols=[\"Time [hh:mm:ss]\", \"Event\", \"Duration[s]\", \"Location\"])\n",
    "    \n",
    "    # Clean column names\n",
    "    data.columns = data.columns.str.strip()\n",
    "    \n",
    "    # Create the 'Class' column\n",
    "    data['Class'] = ((data['Event'].str.contains(\"MCAP\", na=False)) & \n",
    "                     (data['Location'] == \"EEG-Fp2-F4\")).astype(int)\n",
    "    \n",
    "    # Append to the combined DataFrame\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "# Save the combined data to a CSV file\n",
    "output_file = r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\combined_data.csv\"\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "\n",
    "# Preview the saved file path and first few rows of the combined data\n",
    "print(f\"Combined data saved to: {output_file}\")\n",
    "print(combined_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77343a06-d908-4d4d-9be4-f8d993aaf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\features_extracted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ba50eeb-7a93-4764-ac3b-a4ebef983c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3118,  113],\n",
       "        [  16,  771]], dtype=int64),\n",
       " 0.967894474863116,\n",
       " 0.8721719457013575)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and target\n",
    "X = data2.drop(columns=['Class'])\n",
    "y = data2['Class']\n",
    "\n",
    "# Handle missing values using mean imputation\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "\n",
    "# Check for consistent lengths now\n",
    "len(X_imputed), len(y)\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "conf_matrix, accuracy, precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "483d0d8d-af54-4362-a42c-5c2ef9fa3926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Aman Desai/Desktop/sleepEEG/final_corrected_continuous_mcap_events_5.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Reload the new file\n",
    "file_path_new = r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\n5.txt\"\n",
    "\n",
    "# Load the data again and parse\n",
    "with open(file_path_new, 'r') as file:\n",
    "    lines_new = file.readlines()\n",
    "\n",
    "# Identify the table header line and parse the data lines\n",
    "header_line_index_new = next(i for i, line in enumerate(lines_new) if line.startswith(\"Sleep Stage\"))\n",
    "data_lines_new = lines_new[header_line_index_new + 1:]\n",
    "\n",
    "# Extract the columns\n",
    "columns_new = [\"Sleep Stage\", \"Position\", \"Time [hh:mm:ss]\", \"Event\", \"Duration[s]\", \"Location\"]\n",
    "data_new = []\n",
    "\n",
    "# Parse the data lines\n",
    "for line in data_lines_new:\n",
    "    if line.strip():  # Skip empty lines\n",
    "        split_line = line.split('\\t')\n",
    "        if len(split_line) >= len(columns_new):  # Ensure there are enough columns\n",
    "            data_new.append(split_line[:len(columns_new)])\n",
    "\n",
    "# Create a DataFrame\n",
    "df_new = pd.DataFrame(data_new, columns=columns_new)\n",
    "\n",
    "# Define function to convert time to seconds since start (with new start = 0)\n",
    "def time_to_seconds_from_zero(time_str):\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "df_new['Time [hh:mm:ss]'] = df_new['Time [hh:mm:ss]'].str.strip()\n",
    "df_new['Seconds Since Start'] = df_new['Time [hh:mm:ss]'].apply(time_to_seconds_from_zero)\n",
    "\n",
    "# Classify the events (1 for A1, 2 for A2, 3 for A3)\n",
    "def classify_event(event):\n",
    "    if \"MCAP-A1\" in event:\n",
    "        return 1\n",
    "    elif \"MCAP-A2\" in event:\n",
    "        return 2\n",
    "    elif \"MCAP-A3\" in event:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_new['Event Classification'] = df_new['Event'].apply(classify_event)\n",
    "\n",
    "# Repeat rows for each second of event duration if classified (1, 2, or 3)\n",
    "expanded_data_new = []\n",
    "for _, row in df_new.iterrows():\n",
    "    if row['Event Classification'] in [1, 2, 3]:\n",
    "        duration = int(row['Duration[s]'])\n",
    "        for i in range(duration):\n",
    "            expanded_data_new.append({\n",
    "                'Seconds Since Start': row['Seconds Since Start'] + i,\n",
    "                'Event Classification': row['Event Classification']\n",
    "            })\n",
    "    else:\n",
    "        expanded_data_new.append({\n",
    "            'Seconds Since Start': row['Seconds Since Start'],\n",
    "            'Event Classification': 0\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "\n",
    "final_expanded_df_new = pd.DataFrame(expanded_data_new, columns=['Seconds Since Start', 'Event Classification'])\n",
    "\n",
    "\n",
    "# Generate a continuous range starting from 79773 with increments of 1\n",
    "continuous_time = pd.DataFrame({\"Seconds Since Start\": range(82188, final_expanded_df_new[\"Seconds Since Start\"].max() + 1)})\n",
    "\n",
    "# Merge the continuous range with the original data\n",
    "merged_data = pd.merge(continuous_time, final_expanded_df_new, on=\"Seconds Since Start\", how=\"left\")\n",
    "\n",
    "# Impute only the new rows with 0 in \"Event Classification\"\n",
    "merged_data[\"Event Classification\"] = merged_data[\"Event Classification\"].fillna(0).astype(int)\n",
    "\n",
    "# Save the new file with the correct continuous range\n",
    "final_corrected_file_path = r\"C:/Users/Aman Desai/Desktop/sleepEEG/final_corrected_continuous_mcap_events_5.csv\"\n",
    "merged_data.to_csv(final_corrected_file_path, index=False)\n",
    "\n",
    "final_corrected_file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "536fed07-fbe8-4780-8c8b-1b3ac7c462b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mneNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (3.1.3)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (0.3)\n",
      "Requirement already satisfied: matplotlib>=3.6 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (3.8.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (23.1)\n",
      "Collecting pooch>=1.5 (from mne)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (1.11.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from mne) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from pooch>=1.5->mne) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from pooch>=1.5->mne) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from jinja2->mne) (2.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from tqdm->mne) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aman desai\\anaconda3\\lib\\site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2024.2.2)\n",
      "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.4 MB 435.7 kB/s eta 0:00:17\n",
      "   ---------------------------------------- 0.0/7.4 MB 326.8 kB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.0/7.4 MB 326.8 kB/s eta 0:00:23\n",
      "   ---------------------------------------- 0.1/7.4 MB 272.3 kB/s eta 0:00:27\n",
      "   ---------------------------------------- 0.1/7.4 MB 280.5 kB/s eta 0:00:27\n",
      "   ---------------------------------------- 0.1/7.4 MB 327.7 kB/s eta 0:00:23\n",
      "    --------------------------------------- 0.1/7.4 MB 404.6 kB/s eta 0:00:18\n",
      "    --------------------------------------- 0.2/7.4 MB 455.1 kB/s eta 0:00:16\n",
      "   - -------------------------------------- 0.2/7.4 MB 436.8 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.2/7.4 MB 428.5 kB/s eta 0:00:17\n",
      "   - -------------------------------------- 0.3/7.4 MB 516.0 kB/s eta 0:00:14\n",
      "   - -------------------------------------- 0.3/7.4 MB 599.0 kB/s eta 0:00:12\n",
      "   -- ------------------------------------- 0.4/7.4 MB 689.6 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.5/7.4 MB 670.2 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.5/7.4 MB 669.8 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.6/7.4 MB 764.6 kB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 0.7/7.4 MB 925.1 kB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 0.9/7.4 MB 1.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.0/7.4 MB 1.1 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 1.0/7.4 MB 1.1 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.2/7.4 MB 1.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 1.5/7.4 MB 1.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.9/7.4 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.0/7.4 MB 1.8 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.0/7.4 MB 1.8 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.5/7.4 MB 2.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.0/7.4 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.7/7.4 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.1/7.4 MB 3.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 4.2/7.4 MB 2.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 4.8/7.4 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.8/7.4 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.2/7.4 MB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.4/7.4 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.4/7.4 MB 4.6 MB/s eta 0:00:00\n",
      "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.6/64.6 kB 3.4 MB/s eta 0:00:00\n",
      "Installing collected packages: pooch, mne\n",
      "Successfully installed mne-1.9.0 pooch-1.8.2\n"
     ]
    }
   ],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "466d9e03-29fb-49a5-b3e9-76069f566144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Aman Desai/Desktop/sleepEEG/n3_processed.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path =  r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\n3.txt\"\n",
    "\n",
    "# Read the file into a dataframe, skipping the metadata lines\n",
    "data = pd.read_csv(file_path, sep='\\t', skiprows=25, engine='python', names=[\"Stage\", \"Time\", \"Event\", \"Duration[s]\", \"Location\"], skipinitialspace=True)\n",
    "\n",
    "# Drop rows where 'Time' or 'Event' is NaN (invalid rows)\n",
    "data = data.dropna(subset=[\"Time\", \"Event\"]).reset_index(drop=True)\n",
    "\n",
    "# Convert 'Time' to seconds from the start time\n",
    "def time_to_seconds(time_str):\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "start_time = time_to_seconds(\"23:06:12\")  # Starting reference time from the file\n",
    "data['Time in Seconds'] = data['Time'].apply(time_to_seconds) - start_time\n",
    "\n",
    "# Filter only MCAP events\n",
    "mcap_data = data[data['Event'].str.contains('MCAP', na=False)].copy()\n",
    "\n",
    "# Create classifications for MCAP events\n",
    "mcap_data['Classification'] = mcap_data['Event'].apply(lambda x: 1 if 'A1' in x else (2 if 'A2' in x else 3))\n",
    "\n",
    "# Expand rows based on duration\n",
    "expanded_rows = []\n",
    "for _, row in mcap_data.iterrows():\n",
    "    for sec in range(int(row['Duration[s]'])):\n",
    "        expanded_rows.append({\n",
    "            'Time in Seconds': row['Time in Seconds'] + sec,\n",
    "            'Event': row['Event'],\n",
    "            'Classification': row['Classification']\n",
    "        })\n",
    "\n",
    "# Create the expanded dataframe\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Ensure the expanded dataframe covers the full duration (27753 seconds)\n",
    "total_duration = 29969\n",
    "full_time_series = pd.DataFrame({'Time in Seconds': range(total_duration)})\n",
    "\n",
    "# Merge with the expanded data, filling missing values with a default '0' classification\n",
    "result = full_time_series.merge(expanded_df, on='Time in Seconds', how='left').fillna({'Classification': 0})\n",
    "\n",
    "# Finalize output\n",
    "result = result[['Time in Seconds', 'Classification']].astype({'Classification': int})\n",
    "result_path =  r\"C:/Users/Aman Desai/Desktop/sleepEEG/n3_processed.csv\"\n",
    "result.to_csv(result_path, index=False)\n",
    "\n",
    "result_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b033648-019f-454f-94d3-d87fa1113a6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57722 entries, 0 to 57721\n",
      "Data columns (total 8 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ZCR              57722 non-null  float64\n",
      " 1          Variance  57722 non-null  float64\n",
      " 2   Spec_area        57722 non-null  float64\n",
      " 3   Max_freq         57722 non-null  int64  \n",
      " 4     Mean_freq      57722 non-null  float64\n",
      " 5     Skewness       57722 non-null  float64\n",
      " 6     Kurtosis       57722 non-null  float64\n",
      " 7   Classification   57722 non-null  int64  \n",
      "dtypes: float64(6), int64(2)\n",
      "memory usage: 3.5 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        ZCR         Variance  Spec_area      Max_freq    Mean_freq  \\\n",
       " 0  0.005859     8.510000e-10   1.450000e-10         2     3.073657   \n",
       " 1  0.003906     6.690000e-10   1.480000e-10         2     3.978324   \n",
       " 2  0.054688     1.940000e-10   6.430000e-11         4     8.855339   \n",
       " 3  0.019531     7.650000e-10   2.250000e-10         2     4.726932   \n",
       " 4  0.007812     1.140000e-09   4.920000e-10         2     2.982967   \n",
       " \n",
       "      Skewness    Kurtosis  Classification  \n",
       " 0   -0.332677   -1.074932               0  \n",
       " 1    0.262689   -1.198014               0  \n",
       " 2   -0.073477    0.877231               0  \n",
       " 3   -0.464795   -0.151937               0  \n",
       " 4   -0.555812   -0.686807               0  ,\n",
       " None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded file to check its content\n",
    "file_path = r'C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\train_healthy.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "data.head(), data.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3017ecbc-0696-4bd3-a126-c88877dfdd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Desai\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aman Desai\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Aman Desai\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9619748809008228,\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.96      1.00      0.98     11106\\n           1       0.00      0.00      0.00       251\\n           2       0.00      0.00      0.00        83\\n           3       0.00      0.00      0.00       105\\n\\n    accuracy                           0.96     11545\\n   macro avg       0.24      0.25      0.25     11545\\nweighted avg       0.93      0.96      0.94     11545\\n')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Rename columns for consistency (strip leading/trailing spaces)\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = data.drop(columns=[\"Classification\"])\n",
    "y = data[\"Classification\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Initialize and train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "accuracy,report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59400b1a-8a8d-484c-876d-d6e5142f1774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     11106\n",
      "           1       0.00      0.00      0.00       251\n",
      "           2       0.00      0.00      0.00        83\n",
      "           3       0.00      0.00      0.00       105\n",
      "\n",
      "    accuracy                           0.96     11545\n",
      "   macro avg       0.24      0.25      0.25     11545\n",
      "weighted avg       0.93      0.96      0.94     11545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55037193-7d86-4dc7-99e4-44477e86d495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.208955223880597\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.12      0.11        17\n",
      "           1       0.16      0.19      0.17        16\n",
      "           2       0.26      0.29      0.28        17\n",
      "           3       0.36      0.24      0.29        17\n",
      "\n",
      "    accuracy                           0.21        67\n",
      "   macro avg       0.22      0.21      0.21        67\n",
      "weighted avg       0.22      0.21      0.21        67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Load the Data\n",
    "file_path = r'C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\train_healthy.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Step 2: Preprocess the Data\n",
    "# Assuming the last column is the classification column\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target (classification column)\n",
    "\n",
    "# Step 3: Random Sampling\n",
    "# Randomly sample 83 samples from each class (0, 1, 2, 3)\n",
    "sampled_data = pd.concat([\n",
    "    data[data.iloc[:, -1] == 0].sample(n=83, random_state=42),\n",
    "    data[data.iloc[:, -1] == 1].sample(n=83, random_state=42),\n",
    "    data[data.iloc[:, -1] == 2].sample(n=83, random_state=42),\n",
    "    data[data.iloc[:, -1] == 3].sample(n=83, random_state=42)\n",
    "])\n",
    "\n",
    "# Shuffle the sampled data\n",
    "sampled_data = sampled_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Separate features and target for the sampled data\n",
    "X_sampled = sampled_data.iloc[:, :-1]\n",
    "y_sampled = sampled_data.iloc[:, -1]\n",
    "\n",
    "# Step 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_sampled, y_sampled, test_size=0.2, random_state=42, stratify=y_sampled\n",
    ")\n",
    "\n",
    "# Step 5: Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edc46a7-8631-4d00-8417-fc436ed771f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " Classification\n",
      "0    55528\n",
      "1     1252\n",
      "3      527\n",
      "2      415\n",
      "Name: count, dtype: int64\n",
      "Resampled Class Distribution:\n",
      " Classification\n",
      "0    55528\n",
      "3    55528\n",
      "1    55528\n",
      "2    55528\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.965288251581388\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     11106\n",
      "           1       0.96      0.96      0.96     11105\n",
      "           2       0.97      0.99      0.98     11106\n",
      "           3       0.96      0.98      0.97     11106\n",
      "\n",
      "    accuracy                           0.97     44423\n",
      "   macro avg       0.97      0.97      0.97     44423\n",
      "weighted avg       0.97      0.97      0.97     44423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Load the Data\n",
    "file_path = r'C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\train_healthy.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Assuming the last column is the classification column\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target (classification column)\n",
    "\n",
    "# Step 2: Check for Class Imbalance\n",
    "class_distribution = y.value_counts()\n",
    "print(\"Class Distribution:\\n\", class_distribution)\n",
    "\n",
    "# Step 3: Apply Stratified SMOTE or ADASYN\n",
    "# Here, we choose SMOTE. You can switch to ADASYN by replacing SMOTE with ADASYN.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Checking the new class distribution after resampling\n",
    "resampled_class_distribution = pd.Series(y_resampled).value_counts()\n",
    "print(\"Resampled Class Distribution:\\n\", resampled_class_distribution)\n",
    "\n",
    "# Step 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Step 5: Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a727995-0378-4a9c-a436-506704bdbdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Aman Desai/Desktop/sleepEEG/ins_processed3.csv'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the file path\n",
    "file_path =  r\"C:\\Users\\Aman Desai\\Desktop\\sleepEEG\\ins1.txt\"\n",
    "\n",
    "# Read the file into a dataframe, skipping the metadata lines\n",
    "data = pd.read_csv(file_path, sep='\\t', skiprows=25, engine='python', names=[\"Stage\", \"Time\", \"Event\", \"Duration[s]\", \"Location\"], skipinitialspace=True)\n",
    "\n",
    "# Drop rows where 'Time' or 'Event' is NaN (invalid rows)\n",
    "data = data.dropna(subset=[\"Time\", \"Event\"]).reset_index(drop=True)\n",
    "\n",
    "# Convert 'Time' to seconds from the start time\n",
    "def time_to_seconds(time_str):\n",
    "    h, m, s = map(int, time_str.split(':'))\n",
    "    return h * 3600 + m * 60 + s\n",
    "\n",
    "start_time = time_to_seconds(\"22:00:42\")  # Starting reference time from the file\n",
    "data['Time in Seconds'] = data['Time'].apply(time_to_seconds) - start_time\n",
    "\n",
    "# Filter only MCAP events\n",
    "mcap_data = data[data['Event'].str.contains('MCAP', na=False)].copy()\n",
    "\n",
    "# Create classifications for MCAP events\n",
    "mcap_data['Classification'] = mcap_data['Event'].apply(lambda x: 1 if 'A1' in x else (2 if 'A2' in x else 3))\n",
    "\n",
    "# Expand rows based on duration\n",
    "expanded_rows = []\n",
    "for _, row in mcap_data.iterrows():\n",
    "    for sec in range(int(row['Duration[s]'])):\n",
    "        expanded_rows.append({\n",
    "            'Time in Seconds': row['Time in Seconds'] + sec,\n",
    "            'Event': row['Event'],\n",
    "            'Classification': row['Classification']\n",
    "        })\n",
    "\n",
    "# Create the expanded dataframe\n",
    "expanded_df = pd.DataFrame(expanded_rows)\n",
    "\n",
    "# Ensure the expanded dataframe covers the full duration (27753 seconds)\n",
    "total_duration = 25990\n",
    "full_time_series = pd.DataFrame({'Time in Seconds': range(total_duration)})\n",
    "\n",
    "# Merge with the expanded data, filling missing values with a default '0' classification\n",
    "result = full_time_series.merge(expanded_df, on='Time in Seconds', how='left').fillna({'Classification': 0})\n",
    "\n",
    "# Finalize output\n",
    "result = result[['Time in Seconds', 'Classification']].astype({'Classification': int})\n",
    "result_path =  r\"C:/Users/Aman Desai/Desktop/sleepEEG/ins_processed3.csv\"\n",
    "result.to_csv(result_path, index=False)\n",
    "\n",
    "result_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70a91460-8430-48ed-a006-cb5589281a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution:\n",
      " Classification\n",
      "0    102798\n",
      "3       525\n",
      "2       212\n",
      "1       125\n",
      "Name: count, dtype: int64\n",
      "Resampled Class Distribution:\n",
      " Classification\n",
      "0    102798\n",
      "1    102798\n",
      "3    102798\n",
      "2    102798\n",
      "Name: count, dtype: int64\n",
      "Accuracy: 0.9870985785332993\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97     20560\n",
      "           1       0.99      1.00      1.00     20559\n",
      "           2       0.99      1.00      0.99     20560\n",
      "           3       0.98      0.99      0.99     20560\n",
      "\n",
      "    accuracy                           0.99     82239\n",
      "   macro avg       0.99      0.99      0.99     82239\n",
      "weighted avg       0.99      0.99      0.99     82239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Step 1: Load the Data\n",
    "file_path = r\"C:\\Users\\Aman Desai\\Downloads\\ins_features.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming the last column is the classification column\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target (classification column)\n",
    "\n",
    "# Step 2: Check for Class Imbalance\n",
    "class_distribution = y.value_counts()\n",
    "print(\"Class Distribution:\\n\", class_distribution)\n",
    "\n",
    "# Step 3: Apply Stratified SMOTE or ADASYN\n",
    "# Here, we choose SMOTE. You can switch to ADASYN by replacing SMOTE with ADASYN.\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Checking the new class distribution after resampling\n",
    "resampled_class_distribution = pd.Series(y_resampled).value_counts()\n",
    "print(\"Resampled Class Distribution:\\n\", resampled_class_distribution)\n",
    "\n",
    "# Step 4: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# Step 5: Train Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Evaluate the Model\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e814837-013c-498a-a6f2-723f165315e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
